{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b4429d-b523-4d80-b899-43ed870be41b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-22 19:38:49,003] A new study created in memory with name: no-name-839b43a1-9a0c-471c-9555-675621ccfa22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optuna optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 19:47:25,188] Trial 0 finished with value: 3.668514753831667 and parameters: {'n_estimators': 105, 'max_depth': 9, 'learning_rate': 0.010832175019578921, 'subsample': 0.6249674978772852, 'colsample_bytree': 0.9939023088180211}. Best is trial 0 with value: 3.668514753831667.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 19:52:35,635] Trial 1 finished with value: 3.615892207701256 and parameters: {'n_estimators': 80, 'max_depth': 5, 'learning_rate': 0.022538684115441972, 'subsample': 0.7345150477760821, 'colsample_bytree': 0.5786323711008818}. Best is trial 1 with value: 3.615892207701256.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 20:13:48,939] Trial 2 finished with value: 3.551105842111734 and parameters: {'n_estimators': 248, 'max_depth': 7, 'learning_rate': 0.05129596324167866, 'subsample': 0.6252259043941274, 'colsample_bytree': 0.9102142375640712}. Best is trial 2 with value: 3.551105842111734.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 20:39:39,490] Trial 3 finished with value: 3.992198137568356 and parameters: {'n_estimators': 397, 'max_depth': 9, 'learning_rate': 0.17859596254830143, 'subsample': 0.9485990135091166, 'colsample_bytree': 0.5088690428267959}. Best is trial 2 with value: 3.551105842111734.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 21:12:03,580] Trial 4 finished with value: 3.4273762917604937 and parameters: {'n_estimators': 341, 'max_depth': 5, 'learning_rate': 0.019742998791995415, 'subsample': 0.9148006382280481, 'colsample_bytree': 0.5508829418971352}. Best is trial 4 with value: 3.4273762917604937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 341, 'max_depth': 5, 'learning_rate': 0.019742998791995415, 'subsample': 0.9148006382280481, 'colsample_bytree': 0.5508829418971352}\n",
      "Training the optimized model...\n",
      "Validation Log Loss (optimized): 3.4283\n",
      "Feature importances:\n",
      "Feature 1: 0.0025\n",
      "Feature 2: 0.0000\n",
      "Feature 3: 0.0008\n",
      "Feature 4: 0.0005\n",
      "Feature 5: 0.0000\n",
      "Feature 6: 0.0000\n",
      "Feature 7: 0.0007\n",
      "Feature 8: 0.0000\n",
      "Feature 9: 0.0000\n",
      "Feature 10: 0.0000\n",
      "Feature 11: 0.0000\n",
      "Feature 12: 0.0000\n",
      "Feature 13: 0.0000\n",
      "Feature 14: 0.0000\n",
      "Feature 15: 0.0040\n",
      "Feature 16: 0.0000\n",
      "Feature 17: 0.0000\n",
      "Feature 18: 0.0000\n",
      "Feature 19: 0.0000\n",
      "Feature 20: 0.0000\n",
      "Feature 21: 0.0000\n",
      "Feature 22: 0.0000\n",
      "Feature 23: 0.0000\n",
      "Feature 24: 0.0000\n",
      "Feature 25: 0.0000\n",
      "Feature 26: 0.0000\n",
      "Feature 27: 0.0041\n",
      "Feature 28: 0.0009\n",
      "Feature 29: 0.0000\n",
      "Feature 30: 0.0000\n",
      "Feature 31: 0.0040\n",
      "Feature 32: 0.0000\n",
      "Feature 33: 0.0005\n",
      "Feature 34: 0.0006\n",
      "Feature 35: 0.0006\n",
      "Feature 36: 0.0070\n",
      "Feature 37: 0.0000\n",
      "Feature 38: 0.0008\n",
      "Feature 39: 0.0072\n",
      "Feature 40: 0.0000\n",
      "Feature 41: 0.0076\n",
      "Feature 42: 0.0035\n",
      "Feature 43: 0.0000\n",
      "Feature 44: 0.0000\n",
      "Feature 45: 0.0000\n",
      "Feature 46: 0.0007\n",
      "Feature 47: 0.0000\n",
      "Feature 48: 0.0000\n",
      "Feature 49: 0.0078\n",
      "Feature 50: 0.0000\n",
      "Feature 51: 0.0000\n",
      "Feature 52: 0.0000\n",
      "Feature 53: 0.0000\n",
      "Feature 54: 0.0000\n",
      "Feature 55: 0.0112\n",
      "Feature 56: 0.0046\n",
      "Feature 57: 0.0000\n",
      "Feature 58: 0.0019\n",
      "Feature 59: 0.0000\n",
      "Feature 60: 0.0035\n",
      "Feature 61: 0.0000\n",
      "Feature 62: 0.0000\n",
      "Feature 63: 0.0029\n",
      "Feature 64: 0.0000\n",
      "Feature 65: 0.0000\n",
      "Feature 66: 0.0000\n",
      "Feature 67: 0.0000\n",
      "Feature 68: 0.0009\n",
      "Feature 69: 0.0000\n",
      "Feature 70: 0.0000\n",
      "Feature 71: 0.0043\n",
      "Feature 72: 0.0000\n",
      "Feature 73: 0.0036\n",
      "Feature 74: 0.0018\n",
      "Feature 75: 0.0000\n",
      "Feature 76: 0.0007\n",
      "Feature 77: 0.0006\n",
      "Feature 78: 0.0000\n",
      "Feature 79: 0.0000\n",
      "Feature 80: 0.0000\n",
      "Feature 81: 0.0000\n",
      "Feature 82: 0.0010\n",
      "Feature 83: 0.0000\n",
      "Feature 84: 0.0082\n",
      "Feature 85: 0.0036\n",
      "Feature 86: 0.0050\n",
      "Feature 87: 0.0000\n",
      "Feature 88: 0.0000\n",
      "Feature 89: 0.0000\n",
      "Feature 90: 0.0091\n",
      "Feature 91: 0.0000\n",
      "Feature 92: 0.0000\n",
      "Feature 93: 0.0000\n",
      "Feature 94: 0.0000\n",
      "Feature 95: 0.0000\n",
      "Feature 96: 0.0000\n",
      "Feature 97: 0.0000\n",
      "Feature 98: 0.0000\n",
      "Feature 99: 0.0000\n",
      "Feature 100: 0.0000\n",
      "Feature 101: 0.0000\n",
      "Feature 102: 0.0000\n",
      "Feature 103: 0.0000\n",
      "Feature 104: 0.0000\n",
      "Feature 105: 0.0000\n",
      "Feature 106: 0.0000\n",
      "Feature 107: 0.0009\n",
      "Feature 108: 0.0062\n",
      "Feature 109: 0.0000\n",
      "Feature 110: 0.0006\n",
      "Feature 111: 0.0121\n",
      "Feature 112: 0.0000\n",
      "Feature 113: 0.0000\n",
      "Feature 114: 0.0000\n",
      "Feature 115: 0.0000\n",
      "Feature 116: 0.0053\n",
      "Feature 117: 0.0000\n",
      "Feature 118: 0.0000\n",
      "Feature 119: 0.0036\n",
      "Feature 120: 0.0098\n",
      "Feature 121: 0.0057\n",
      "Feature 122: 0.0000\n",
      "Feature 123: 0.0000\n",
      "Feature 124: 0.0044\n",
      "Feature 125: 0.0000\n",
      "Feature 126: 0.0000\n",
      "Feature 127: 0.0000\n",
      "Feature 128: 0.0053\n",
      "Feature 129: 0.0000\n",
      "Feature 130: 0.0054\n",
      "Feature 131: 0.0000\n",
      "Feature 132: 0.0000\n",
      "Feature 133: 0.0000\n",
      "Feature 134: 0.0000\n",
      "Feature 135: 0.0000\n",
      "Feature 136: 0.0000\n",
      "Feature 137: 0.0008\n",
      "Feature 138: 0.0000\n",
      "Feature 139: 0.0004\n",
      "Feature 140: 0.0000\n",
      "Feature 141: 0.0000\n",
      "Feature 142: 0.0000\n",
      "Feature 143: 0.0000\n",
      "Feature 144: 0.0000\n",
      "Feature 145: 0.0000\n",
      "Feature 146: 0.0000\n",
      "Feature 147: 0.0000\n",
      "Feature 148: 0.0000\n",
      "Feature 149: 0.0000\n",
      "Feature 150: 0.0000\n",
      "Feature 151: 0.0000\n",
      "Feature 152: 0.0000\n",
      "Feature 153: 0.0111\n",
      "Feature 154: 0.0000\n",
      "Feature 155: 0.0000\n",
      "Feature 156: 0.0016\n",
      "Feature 157: 0.0000\n",
      "Feature 158: 0.0000\n",
      "Feature 159: 0.0000\n",
      "Feature 160: 0.0134\n",
      "Feature 161: 0.0017\n",
      "Feature 162: 0.0000\n",
      "Feature 163: 0.0011\n",
      "Feature 164: 0.0000\n",
      "Feature 165: 0.0085\n",
      "Feature 166: 0.0061\n",
      "Feature 167: 0.0033\n",
      "Feature 168: 0.0055\n",
      "Feature 169: 0.0000\n",
      "Feature 170: 0.0000\n",
      "Feature 171: 0.0043\n",
      "Feature 172: 0.0011\n",
      "Feature 173: 0.0000\n",
      "Feature 174: 0.0096\n",
      "Feature 175: 0.0002\n",
      "Feature 176: 0.0000\n",
      "Feature 177: 0.0097\n",
      "Feature 178: 0.0000\n",
      "Feature 179: 0.0034\n",
      "Feature 180: 0.0000\n",
      "Feature 181: 0.0034\n",
      "Feature 182: 0.0000\n",
      "Feature 183: 0.0067\n",
      "Feature 184: 0.0000\n",
      "Feature 185: 0.0000\n",
      "Feature 186: 0.0024\n",
      "Feature 187: 0.0000\n",
      "Feature 188: 0.0000\n",
      "Feature 189: 0.0000\n",
      "Feature 190: 0.0000\n",
      "Feature 191: 0.0000\n",
      "Feature 192: 0.0000\n",
      "Feature 193: 0.0041\n",
      "Feature 194: 0.0000\n",
      "Feature 195: 0.0035\n",
      "Feature 196: 0.0000\n",
      "Feature 197: 0.0000\n",
      "Feature 198: 0.0000\n",
      "Feature 199: 0.0000\n",
      "Feature 200: 0.0000\n",
      "Feature 201: 0.0051\n",
      "Feature 202: 0.0000\n",
      "Feature 203: 0.0000\n",
      "Feature 204: 0.0100\n",
      "Feature 205: 0.0000\n",
      "Feature 206: 0.0000\n",
      "Feature 207: 0.0035\n",
      "Feature 208: 0.0000\n",
      "Feature 209: 0.0000\n",
      "Feature 210: 0.0000\n",
      "Feature 211: 0.0020\n",
      "Feature 212: 0.0000\n",
      "Feature 213: 0.0000\n",
      "Feature 214: 0.0000\n",
      "Feature 215: 0.0000\n",
      "Feature 216: 0.0000\n",
      "Feature 217: 0.0000\n",
      "Feature 218: 0.0000\n",
      "Feature 219: 0.0006\n",
      "Feature 220: 0.0000\n",
      "Feature 221: 0.0000\n",
      "Feature 222: 0.0031\n",
      "Feature 223: 0.0000\n",
      "Feature 224: 0.0000\n",
      "Feature 225: 0.0000\n",
      "Feature 226: 0.0000\n",
      "Feature 227: 0.0125\n",
      "Feature 228: 0.0000\n",
      "Feature 229: 0.0000\n",
      "Feature 230: 0.0000\n",
      "Feature 231: 0.0095\n",
      "Feature 232: 0.0103\n",
      "Feature 233: 0.0000\n",
      "Feature 234: 0.0000\n",
      "Feature 235: 0.0086\n",
      "Feature 236: 0.0000\n",
      "Feature 237: 0.0000\n",
      "Feature 238: 0.0000\n",
      "Feature 239: 0.0069\n",
      "Feature 240: 0.0112\n",
      "Feature 241: 0.0000\n",
      "Feature 242: 0.0000\n",
      "Feature 243: 0.0000\n",
      "Feature 244: 0.0024\n",
      "Feature 245: 0.0005\n",
      "Feature 246: 0.0000\n",
      "Feature 247: 0.0000\n",
      "Feature 248: 0.0000\n",
      "Feature 249: 0.0000\n",
      "Feature 250: 0.0000\n",
      "Feature 251: 0.0011\n",
      "Feature 252: 0.0000\n",
      "Feature 253: 0.0061\n",
      "Feature 254: 0.0006\n",
      "Feature 255: 0.0010\n",
      "Feature 256: 0.0000\n",
      "Feature 257: 0.0042\n",
      "Feature 258: 0.0057\n",
      "Feature 259: 0.0045\n",
      "Feature 260: 0.0153\n",
      "Feature 261: 0.0038\n",
      "Feature 262: 0.0034\n",
      "Feature 263: 0.0127\n",
      "Feature 264: 0.0000\n",
      "Feature 265: 0.0000\n",
      "Feature 266: 0.0000\n",
      "Feature 267: 0.0026\n",
      "Feature 268: 0.0000\n",
      "Feature 269: 0.0000\n",
      "Feature 270: 0.0018\n",
      "Feature 271: 0.0000\n",
      "Feature 272: 0.0000\n",
      "Feature 273: 0.0000\n",
      "Feature 274: 0.0000\n",
      "Feature 275: 0.0000\n",
      "Feature 276: 0.0028\n",
      "Feature 277: 0.0056\n",
      "Feature 278: 0.0000\n",
      "Feature 279: 0.0026\n",
      "Feature 280: 0.0009\n",
      "Feature 281: 0.0000\n",
      "Feature 282: 0.0000\n",
      "Feature 283: 0.0000\n",
      "Feature 284: 0.0034\n",
      "Feature 285: 0.0000\n",
      "Feature 286: 0.0000\n",
      "Feature 287: 0.0000\n",
      "Feature 288: 0.0000\n",
      "Feature 289: 0.0058\n",
      "Feature 290: 0.0000\n",
      "Feature 291: 0.0000\n",
      "Feature 292: 0.0000\n",
      "Feature 293: 0.0037\n",
      "Feature 294: 0.0117\n",
      "Feature 295: 0.0000\n",
      "Feature 296: 0.0000\n",
      "Feature 297: 0.0000\n",
      "Feature 298: 0.0033\n",
      "Feature 299: 0.0140\n",
      "Feature 300: 0.0000\n",
      "Feature 301: 0.0000\n",
      "Feature 302: 0.0025\n",
      "Feature 303: 0.0000\n",
      "Feature 304: 0.0000\n",
      "Feature 305: 0.0035\n",
      "Feature 306: 0.0000\n",
      "Feature 307: 0.0086\n",
      "Feature 308: 0.0008\n",
      "Feature 309: 0.0099\n",
      "Feature 310: 0.0039\n",
      "Feature 311: 0.0000\n",
      "Feature 312: 0.0000\n",
      "Feature 313: 0.0000\n",
      "Feature 314: 0.0110\n",
      "Feature 315: 0.0000\n",
      "Feature 316: 0.0000\n",
      "Feature 317: 0.0044\n",
      "Feature 318: 0.0000\n",
      "Feature 319: 0.0000\n",
      "Feature 320: 0.0059\n",
      "Feature 321: 0.0000\n",
      "Feature 322: 0.0000\n",
      "Feature 323: 0.0000\n",
      "Feature 324: 0.0000\n",
      "Feature 325: 0.0000\n",
      "Feature 326: 0.0000\n",
      "Feature 327: 0.0007\n",
      "Feature 328: 0.0011\n",
      "Feature 329: 0.0000\n",
      "Feature 330: 0.0090\n",
      "Feature 331: 0.0000\n",
      "Feature 332: 0.0027\n",
      "Feature 333: 0.0053\n",
      "Feature 334: 0.0000\n",
      "Feature 335: 0.0000\n",
      "Feature 336: 0.0008\n",
      "Feature 337: 0.0000\n",
      "Feature 338: 0.0063\n",
      "Feature 339: 0.0000\n",
      "Feature 340: 0.0000\n",
      "Feature 341: 0.0000\n",
      "Feature 342: 0.0024\n",
      "Feature 343: 0.0134\n",
      "Feature 344: 0.0000\n",
      "Feature 345: 0.0020\n",
      "Feature 346: 0.0014\n",
      "Feature 347: 0.0057\n",
      "Feature 348: 0.0000\n",
      "Feature 349: 0.0029\n",
      "Feature 350: 0.0000\n",
      "Feature 351: 0.0000\n",
      "Feature 352: 0.0030\n",
      "Feature 353: 0.0000\n",
      "Feature 354: 0.0000\n",
      "Feature 355: 0.0000\n",
      "Feature 356: 0.0000\n",
      "Feature 357: 0.0000\n",
      "Feature 358: 0.0050\n",
      "Feature 359: 0.0000\n",
      "Feature 360: 0.0056\n",
      "Feature 361: 0.0140\n",
      "Feature 362: 0.0020\n",
      "Feature 363: 0.0045\n",
      "Feature 364: 0.0000\n",
      "Feature 365: 0.0000\n",
      "Feature 366: 0.0068\n",
      "Feature 367: 0.0000\n",
      "Feature 368: 0.0000\n",
      "Feature 369: 0.0141\n",
      "Feature 370: 0.0000\n",
      "Feature 371: 0.0000\n",
      "Feature 372: 0.0041\n",
      "Feature 373: 0.0000\n",
      "Feature 374: 0.0117\n",
      "Feature 375: 0.0000\n",
      "Feature 376: 0.0000\n",
      "Feature 377: 0.0064\n",
      "Feature 378: 0.0022\n",
      "Feature 379: 0.0000\n",
      "Feature 380: 0.0022\n",
      "Feature 381: 0.0000\n",
      "Feature 382: 0.0000\n",
      "Feature 383: 0.0011\n",
      "Feature 384: 0.0005\n",
      "Feature 385: 0.0000\n",
      "Feature 386: 0.0000\n",
      "Feature 387: 0.0000\n",
      "Feature 388: 0.0000\n",
      "Feature 389: 0.0006\n",
      "Feature 390: 0.0041\n",
      "Feature 391: 0.0000\n",
      "Feature 392: 0.0000\n",
      "Feature 393: 0.0091\n",
      "Feature 394: 0.0000\n",
      "Feature 395: 0.0038\n",
      "Feature 396: 0.0000\n",
      "Feature 397: 0.0078\n",
      "Feature 398: 0.0000\n",
      "Feature 399: 0.0110\n",
      "Feature 400: 0.0000\n",
      "Feature 401: 0.0022\n",
      "Feature 402: 0.0000\n",
      "Feature 403: 0.0031\n",
      "Feature 404: 0.0000\n",
      "Feature 405: 0.0000\n",
      "Feature 406: 0.0033\n",
      "Feature 407: 0.0024\n",
      "Feature 408: 0.0000\n",
      "Feature 409: 0.0007\n",
      "Feature 410: 0.0093\n",
      "Feature 411: 0.0099\n",
      "Feature 412: 0.0006\n",
      "Feature 413: 0.0006\n",
      "Feature 414: 0.0000\n",
      "Feature 415: 0.0000\n",
      "Feature 416: 0.0000\n",
      "Feature 417: 0.0000\n",
      "Feature 418: 0.0011\n",
      "Feature 419: 0.0000\n",
      "Feature 420: 0.0000\n",
      "Feature 421: 0.0052\n",
      "Feature 422: 0.0000\n",
      "Feature 423: 0.0000\n",
      "Feature 424: 0.0038\n",
      "Feature 425: 0.0000\n",
      "Feature 426: 0.0092\n",
      "Feature 427: 0.0018\n",
      "Feature 428: 0.0010\n",
      "Feature 429: 0.0046\n",
      "Feature 430: 0.0000\n",
      "Feature 431: 0.0000\n",
      "Feature 432: 0.0000\n",
      "Feature 433: 0.0042\n",
      "Feature 434: 0.0000\n",
      "Feature 435: 0.0000\n",
      "Feature 436: 0.0085\n",
      "Feature 437: 0.0007\n",
      "Feature 438: 0.0000\n",
      "Feature 439: 0.0000\n",
      "Feature 440: 0.0032\n",
      "Feature 441: 0.0005\n",
      "Feature 442: 0.0000\n",
      "Feature 443: 0.0000\n",
      "Feature 444: 0.0068\n",
      "Feature 445: 0.0046\n",
      "Feature 446: 0.0000\n",
      "Feature 447: 0.0000\n",
      "Feature 448: 0.0000\n",
      "Feature 449: 0.0032\n",
      "Feature 450: 0.0099\n",
      "Feature 451: 0.0047\n",
      "Feature 452: 0.0000\n",
      "Feature 453: 0.0042\n",
      "Feature 454: 0.0066\n",
      "Feature 455: 0.0000\n",
      "Feature 456: 0.0065\n",
      "Feature 457: 0.0000\n",
      "Feature 458: 0.0000\n",
      "Feature 459: 0.0000\n",
      "Feature 460: 0.0000\n",
      "Feature 461: 0.0000\n",
      "Feature 462: 0.0000\n",
      "Feature 463: 0.0000\n",
      "Feature 464: 0.0006\n",
      "Feature 465: 0.0136\n",
      "Feature 466: 0.0000\n",
      "Feature 467: 0.0041\n",
      "Feature 468: 0.0009\n",
      "Feature 469: 0.0000\n",
      "Feature 470: 0.0019\n",
      "Feature 471: 0.0000\n",
      "Feature 472: 0.0057\n",
      "Feature 473: 0.0030\n",
      "Feature 474: 0.0105\n",
      "Feature 475: 0.0000\n",
      "Feature 476: 0.0000\n",
      "Feature 477: 0.0105\n",
      "Feature 478: 0.0072\n",
      "Feature 479: 0.0000\n",
      "Feature 480: 0.0009\n",
      "Feature 481: 0.0007\n",
      "Feature 482: 0.0140\n",
      "Feature 483: 0.0085\n",
      "Feature 484: 0.0006\n",
      "Feature 485: 0.0000\n",
      "Feature 486: 0.0000\n",
      "Feature 487: 0.0000\n",
      "Feature 488: 0.0000\n",
      "Feature 489: 0.0027\n",
      "Feature 490: 0.0086\n",
      "Feature 491: 0.0006\n",
      "Feature 492: 0.0000\n",
      "Feature 493: 0.0000\n",
      "Feature 494: 0.0000\n",
      "Feature 495: 0.0053\n",
      "Feature 496: 0.0013\n",
      "Feature 497: 0.0061\n",
      "Feature 498: 0.0000\n",
      "Feature 499: 0.0000\n",
      "Feature 500: 0.0010\n",
      "Feature 501: 0.0056\n",
      "Feature 502: 0.0000\n",
      "Feature 503: 0.0000\n",
      "Feature 504: 0.0042\n",
      "Feature 505: 0.0000\n",
      "Feature 506: 0.0018\n",
      "Feature 507: 0.0000\n",
      "Feature 508: 0.0033\n",
      "Feature 509: 0.0000\n",
      "Feature 510: 0.0033\n",
      "Feature 511: 0.0000\n",
      "Feature 512: 0.0030\n",
      "Feature 513: 0.0000\n",
      "Feature 514: 0.0000\n",
      "Feature 515: 0.0031\n",
      "Feature 516: 0.0064\n",
      "Feature 517: 0.0041\n",
      "Feature 518: 0.0000\n",
      "Feature 519: 0.0000\n",
      "Feature 520: 0.0006\n",
      "Feature 521: 0.0032\n",
      "Feature 522: 0.0008\n",
      "Feature 523: 0.0000\n",
      "Feature 524: 0.0045\n",
      "Feature 525: 0.0000\n",
      "Feature 526: 0.0006\n",
      "Feature 527: 0.0000\n",
      "Feature 528: 0.0000\n",
      "Feature 529: 0.0000\n",
      "Feature 530: 0.0000\n",
      "Feature 531: 0.0030\n",
      "Feature 532: 0.0000\n",
      "Feature 533: 0.0039\n",
      "Feature 534: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2910: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "\n",
    "# load data\n",
    "train_features = pd.read_csv(\"train_features.csv\")\n",
    "train_targets = pd.read_csv(\"train_targets_scored.csv\")\n",
    "\n",
    "# Increase the fraction of data used for training\n",
    "fraction = 0.4  # Use a larger fraction of data\n",
    "train_features = train_features.sample(frac=fraction, random_state=42).reset_index(drop=True)\n",
    "train_targets = train_targets.loc[train_features.index].reset_index(drop=True)\n",
    "\n",
    "# Preprocessing\n",
    "X = train_features.drop(columns=[\"sig_id\"])\n",
    "y = train_targets.drop(columns=[\"sig_id\"])\n",
    "\n",
    "# Encoding of categorical features\n",
    "X = pd.get_dummies(X, columns=[\"cp_type\", \"cp_time\", \"cp_dose\"], drop_first=True)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X[X.columns] = scaler.fit_transform(X[X.columns])\n",
    "\n",
    "# Apply Principal Component Analysis (PCA)\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define an Optuna objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 400),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "    model = MultiOutputClassifier(XGBClassifier(**param, eval_metric='logloss'))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = np.column_stack([\n",
    "        clf.predict_proba(X_val)[:, 1] for clf in model.estimators_\n",
    "    ])\n",
    "    return log_loss(y_val, y_val_pred, eps=1e-15)\n",
    "\n",
    "# optuna optimization\n",
    "print(\"Starting Optuna optimization...\")\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=3)\n",
    "\n",
    "# parameters from Optuna\n",
    "best_params = study.best_params\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# training optimized Model\n",
    "print(\"Training the optimized model...\")\n",
    "optimized_model = MultiOutputClassifier(XGBClassifier(**best_params, eval_metric='logloss'))\n",
    "optimized_model.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "y_val_pred = np.column_stack([\n",
    "    clf.predict_proba(X_val)[:, 1] for clf in optimized_model.estimators_\n",
    "])\n",
    "\n",
    "# log loss\n",
    "log_loss_score = log_loss(y_val, y_val_pred, eps=1e-15)\n",
    "print(f\"Validation Log Loss (optimized): {log_loss_score:.4f}\")\n",
    "\n",
    "# Feature importance listing\n",
    "feature_importances = optimized_model.estimators_[0].feature_importances_\n",
    "print(\"Feature importances:\")\n",
    "for i, importance in enumerate(feature_importances):\n",
    "    print(f\"Feature {i + 1}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7935637-5e5d-4c10-a76d-292401baf59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39fc507-78c0-4690-9ddc-3c5dac5121ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
